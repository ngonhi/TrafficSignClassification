{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RF_SIFT_ori","provenance":[],"mount_file_id":"1HLeGil5_sHyw8KQM7uEfgwC1Lcw8dlhR","authorship_tag":"ABX9TyOQ0CDsDil2mAu1fVgA/SoP"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"3-bHnV3kJWG5","executionInfo":{"status":"ok","timestamp":1608971992724,"user_tz":-420,"elapsed":785,"user":{"displayName":"Nhi Ngo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT3hv8kT-LPPVVfov1HHd0nw5NDCvBdYck4b7v-Q=s64","userId":"16422571029059227305"}}},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import os, glob\r\n","import pickle\r\n","import pandas as pd\r\n","import cv2 as cv\r\n","%matplotlib inline\r\n","\r\n","# classification required packages\r\n","\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","from sklearn.model_selection import cross_val_score, train_test_split\r\n","from sklearn.metrics import classification_report\r\n","import joblib\r\n","\r\n","import warnings\r\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\r\n","%matplotlib inline"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2CJyAvIKF7O","executionInfo":{"status":"ok","timestamp":1608971920070,"user_tz":-420,"elapsed":1131,"user":{"displayName":"Nhi Ngo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT3hv8kT-LPPVVfov1HHd0nw5NDCvBdYck4b7v-Q=s64","userId":"16422571029059227305"}}},"source":["def load_data(filedir, filepath, csvfile):\r\n","    data = np.load(os.path.join(filedir, filepath), allow_pickle=True)\r\n","    train_info = pd.read_csv(os.path.join(filedir, csvfile))\r\n","    labels = np.array(train_info['ClassId'])\r\n","    \r\n","    return data, labels\r\n","\r\n","def randomize_data(data, labels):\r\n","    randomize = np.arange(len(labels))\r\n","    np.random.shuffle(randomize)\r\n","    X = data[randomize]\r\n","    y = labels[randomize]\r\n","    \r\n","    return X,y\r\n","  "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"EuolcdFQKGlA","executionInfo":{"status":"ok","timestamp":1608971920489,"user_tz":-420,"elapsed":549,"user":{"displayName":"Nhi Ngo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT3hv8kT-LPPVVfov1HHd0nw5NDCvBdYck4b7v-Q=s64","userId":"16422571029059227305"}}},"source":["data_dir = '/content/drive/MyDrive/GTSRB'\r\n","ori_train_path = '/content/drive/MyDrive/Kaggle/Sift&BowTest/Sift&BowPreprocess_train.npy'\r\n","ori_test_path = '/content/drive/MyDrive/Kaggle/Sift&BowTest/Sift&BowPreprocess_test.npy'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRIXEDKFKLcb","executionInfo":{"status":"ok","timestamp":1608971921952,"user_tz":-420,"elapsed":951,"user":{"displayName":"Nhi Ngo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT3hv8kT-LPPVVfov1HHd0nw5NDCvBdYck4b7v-Q=s64","userId":"16422571029059227305"}},"outputId":"1f86dbe0-3536-4290-9265-8dcbad2006a5"},"source":["trainOriData, trainLabels = load_data(data_dir, ori_train_path, 'Train.csv')\r\n","trainOriData, trainLabels = randomize_data(trainOriData, trainLabels)\r\n","trainOriData.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(39209, 150)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33EpjdWFKMzY","executionInfo":{"status":"ok","timestamp":1608971973462,"user_tz":-420,"elapsed":948,"user":{"displayName":"Nhi Ngo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT3hv8kT-LPPVVfov1HHd0nw5NDCvBdYck4b7v-Q=s64","userId":"16422571029059227305"}},"outputId":"48e38efc-4586-4ed9-ad15-bfb2c8a91a6f"},"source":["testOriData, testLabels = load_data(data_dir, ori_test_path, 'Test.csv')\r\n","testOriData.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12630, 150)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"hfGkb-q_KPPF","executionInfo":{"status":"ok","timestamp":1608972304045,"user_tz":-420,"elapsed":999,"user":{"displayName":"Nhi Ngo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT3hv8kT-LPPVVfov1HHd0nw5NDCvBdYck4b7v-Q=s64","userId":"16422571029059227305"}}},"source":["estimators= [50,100,150,200]\r\n","def train_model(estimators, trainData, trainLabels, testData, testLabels):\r\n","    for n in estimators:\r\n","        print(f'RANDOM FOREST WITH {n} ESTIMATORS')\r\n","        if os.path.isfile(\"/content/drive/MyDrive/Kaggle/clf/rf_\"+str(n)+\"_sift_ori.pkl\"):\r\n","            print(\"[INFO] loading classifier: Random Forest trained on ori images...\")\r\n","            rf = pickle.load(open(\"/content/drive/MyDrive/Kaggle/clf/rf_\"+str(n)+\"_sift_ori.pkl\", 'rb'))\r\n","            print(\"[INFO] Classifer is loaded as instance ::rf::\")\r\n","        else:\r\n","            print(\"[INFO] pre-trained classifier not found. \\n Training Classifier Random Forest\")\r\n","            rf = RandomForestClassifier(n_estimators=n, class_weight='balanced')\r\n","            rf.fit(trainData.reshape(len(trainLabels), -1),trainLabels)\r\n","            print(\"[INFO] Succefully trained the classsifier. \\n Saving the classifier for further use\")\r\n","            pickle.dump(rf, open(\"/content/drive/MyDrive/Kaggle/clf/rf_\"+str(n)+\"_sift_ori.pkl\", 'wb')) \r\n","            print(\"[INFO] Classifier Saved\")\r\n","            \r\n","        predictions = rf.predict(testData.reshape(len(testLabels), -1))\r\n"," \r\n","        # show a final classification report demonstrating the accuracy of the classifier\r\n","        print(\"EVALUATION ON TESTING DATA FOR\" + str(n) + 'FOREST')\r\n","        print(classification_report(testLabels, predictions))\r\n","        \r\n","        print('ACCURACY of TRAINING DATA')\r\n","        print(rf.score(trainData, trainLabels))\r\n","        print('-------------------------------------------------------')"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBE6xVa8MneT","executionInfo":{"status":"ok","timestamp":1608972452863,"user_tz":-420,"elapsed":149795,"user":{"displayName":"Nhi Ngo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiT3hv8kT-LPPVVfov1HHd0nw5NDCvBdYck4b7v-Q=s64","userId":"16422571029059227305"}},"outputId":"0cdc5ee5-03c5-4b82-e600-6b6adc6b07d9"},"source":["train_model(estimators, trainOriData, trainLabels, testOriData, testLabels)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["RANDOM FOREST WITH 50 ESTIMATORS\n","[INFO] pre-trained classifier not found. \n"," Training Classifier Random Forest\n","[INFO] Succefully trained the classsifier. \n"," Saving the classifier for further use\n","[INFO] Classifier Saved\n","EVALUATION ON TESTING DATA FOR50FOREST\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.15      0.25        60\n","           1       0.68      0.62      0.65       720\n","           2       0.67      0.67      0.67       750\n","           3       0.36      0.34      0.35       450\n","           4       0.51      0.34      0.41       660\n","           5       0.53      0.54      0.54       630\n","           6       0.38      0.27      0.32       150\n","           7       0.57      0.59      0.58       450\n","           8       0.16      0.53      0.25       450\n","           9       0.73      0.56      0.63       480\n","          10       0.60      0.53      0.57       660\n","          11       0.77      0.67      0.71       420\n","          12       0.54      0.59      0.56       690\n","          13       0.57      0.72      0.64       720\n","          14       0.67      0.61      0.64       270\n","          15       0.53      0.55      0.54       210\n","          16       0.69      0.64      0.66       150\n","          17       0.62      0.69      0.65       360\n","          18       0.50      0.45      0.47       390\n","          19       0.58      0.42      0.49        60\n","          20       0.52      0.57      0.54        90\n","          21       0.34      0.16      0.21        90\n","          22       0.56      0.64      0.60       120\n","          23       0.48      0.32      0.39       150\n","          24       0.25      0.10      0.14        90\n","          25       0.67      0.74      0.70       480\n","          26       0.67      0.63      0.65       180\n","          27       0.60      0.42      0.49        60\n","          28       0.62      0.45      0.53       150\n","          29       0.39      0.22      0.28        90\n","          30       0.38      0.23      0.28       150\n","          31       0.65      0.63      0.64       270\n","          32       0.24      0.75      0.36        60\n","          33       0.43      0.24      0.31       210\n","          34       0.38      0.24      0.29       120\n","          35       0.25      0.21      0.23       390\n","          36       0.44      0.46      0.45       120\n","          37       0.27      0.18      0.22        60\n","          38       0.45      0.37      0.41       690\n","          39       0.18      0.08      0.11        90\n","          40       0.73      0.49      0.59        90\n","          41       0.29      0.20      0.24        60\n","          42       0.53      0.31      0.39        90\n","\n","    accuracy                           0.51     12630\n","   macro avg       0.51      0.44      0.46     12630\n","weighted avg       0.54      0.51      0.52     12630\n","\n","ACCURACY of TRAINING DATA\n","0.8876278405468132\n","-------------------------------------------------------\n","RANDOM FOREST WITH 100 ESTIMATORS\n","[INFO] pre-trained classifier not found. \n"," Training Classifier Random Forest\n","[INFO] Succefully trained the classsifier. \n"," Saving the classifier for further use\n","[INFO] Classifier Saved\n","EVALUATION ON TESTING DATA FOR100FOREST\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.17      0.28        60\n","           1       0.72      0.62      0.67       720\n","           2       0.69      0.68      0.69       750\n","           3       0.36      0.34      0.35       450\n","           4       0.55      0.35      0.43       660\n","           5       0.52      0.54      0.53       630\n","           6       0.42      0.29      0.34       150\n","           7       0.56      0.58      0.57       450\n","           8       0.16      0.52      0.24       450\n","           9       0.73      0.57      0.64       480\n","          10       0.61      0.53      0.57       660\n","          11       0.76      0.66      0.70       420\n","          12       0.54      0.58      0.56       690\n","          13       0.58      0.72      0.64       720\n","          14       0.67      0.64      0.65       270\n","          15       0.53      0.56      0.55       210\n","          16       0.62      0.65      0.63       150\n","          17       0.64      0.70      0.67       360\n","          18       0.47      0.44      0.45       390\n","          19       0.53      0.42      0.47        60\n","          20       0.56      0.54      0.55        90\n","          21       0.36      0.18      0.24        90\n","          22       0.55      0.64      0.59       120\n","          23       0.48      0.38      0.43       150\n","          24       0.28      0.12      0.17        90\n","          25       0.66      0.74      0.70       480\n","          26       0.69      0.62      0.65       180\n","          27       0.62      0.40      0.48        60\n","          28       0.63      0.42      0.50       150\n","          29       0.40      0.21      0.28        90\n","          30       0.35      0.23      0.28       150\n","          31       0.65      0.63      0.64       270\n","          32       0.24      0.72      0.36        60\n","          33       0.41      0.22      0.29       210\n","          34       0.27      0.14      0.19       120\n","          35       0.29      0.22      0.25       390\n","          36       0.53      0.50      0.51       120\n","          37       0.31      0.25      0.28        60\n","          38       0.48      0.42      0.45       690\n","          39       0.11      0.04      0.06        90\n","          40       0.63      0.42      0.51        90\n","          41       0.32      0.18      0.23        60\n","          42       0.44      0.31      0.37        90\n","\n","    accuracy                           0.52     12630\n","   macro avg       0.51      0.45      0.46     12630\n","weighted avg       0.55      0.52      0.52     12630\n","\n","ACCURACY of TRAINING DATA\n","0.8876278405468132\n","-------------------------------------------------------\n","RANDOM FOREST WITH 150 ESTIMATORS\n","[INFO] pre-trained classifier not found. \n"," Training Classifier Random Forest\n","[INFO] Succefully trained the classsifier. \n"," Saving the classifier for further use\n","[INFO] Classifier Saved\n","EVALUATION ON TESTING DATA FOR150FOREST\n","              precision    recall  f1-score   support\n","\n","           0       0.90      0.15      0.26        60\n","           1       0.71      0.62      0.66       720\n","           2       0.69      0.68      0.68       750\n","           3       0.35      0.34      0.35       450\n","           4       0.53      0.34      0.41       660\n","           5       0.53      0.55      0.54       630\n","           6       0.42      0.28      0.34       150\n","           7       0.56      0.59      0.58       450\n","           8       0.16      0.53      0.25       450\n","           9       0.74      0.57      0.64       480\n","          10       0.61      0.54      0.57       660\n","          11       0.77      0.67      0.71       420\n","          12       0.55      0.59      0.57       690\n","          13       0.57      0.72      0.64       720\n","          14       0.63      0.63      0.63       270\n","          15       0.58      0.59      0.58       210\n","          16       0.68      0.64      0.66       150\n","          17       0.62      0.71      0.66       360\n","          18       0.50      0.46      0.48       390\n","          19       0.61      0.42      0.50        60\n","          20       0.52      0.56      0.53        90\n","          21       0.34      0.16      0.21        90\n","          22       0.60      0.63      0.62       120\n","          23       0.45      0.31      0.37       150\n","          24       0.25      0.11      0.15        90\n","          25       0.66      0.74      0.70       480\n","          26       0.68      0.65      0.67       180\n","          27       0.60      0.43      0.50        60\n","          28       0.57      0.42      0.48       150\n","          29       0.40      0.21      0.28        90\n","          30       0.36      0.24      0.29       150\n","          31       0.65      0.62      0.64       270\n","          32       0.25      0.73      0.37        60\n","          33       0.36      0.21      0.27       210\n","          34       0.33      0.17      0.22       120\n","          35       0.28      0.23      0.25       390\n","          36       0.47      0.45      0.46       120\n","          37       0.30      0.22      0.25        60\n","          38       0.47      0.41      0.43       690\n","          39       0.05      0.02      0.03        90\n","          40       0.69      0.46      0.55        90\n","          41       0.30      0.18      0.23        60\n","          42       0.43      0.29      0.34        90\n","\n","    accuracy                           0.52     12630\n","   macro avg       0.51      0.44      0.45     12630\n","weighted avg       0.54      0.52      0.52     12630\n","\n","ACCURACY of TRAINING DATA\n","0.8874238057588819\n","-------------------------------------------------------\n","RANDOM FOREST WITH 200 ESTIMATORS\n","[INFO] pre-trained classifier not found. \n"," Training Classifier Random Forest\n","[INFO] Succefully trained the classsifier. \n"," Saving the classifier for further use\n","[INFO] Classifier Saved\n","EVALUATION ON TESTING DATA FOR200FOREST\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.13      0.24        60\n","           1       0.71      0.63      0.67       720\n","           2       0.70      0.68      0.69       750\n","           3       0.35      0.34      0.35       450\n","           4       0.56      0.35      0.43       660\n","           5       0.54      0.56      0.55       630\n","           6       0.41      0.27      0.33       150\n","           7       0.56      0.60      0.58       450\n","           8       0.16      0.52      0.24       450\n","           9       0.74      0.56      0.64       480\n","          10       0.60      0.53      0.56       660\n","          11       0.77      0.69      0.73       420\n","          12       0.56      0.61      0.58       690\n","          13       0.59      0.72      0.65       720\n","          14       0.66      0.64      0.65       270\n","          15       0.59      0.61      0.60       210\n","          16       0.68      0.67      0.68       150\n","          17       0.65      0.71      0.68       360\n","          18       0.49      0.46      0.48       390\n","          19       0.64      0.42      0.51        60\n","          20       0.55      0.57      0.56        90\n","          21       0.31      0.14      0.20        90\n","          22       0.59      0.63      0.61       120\n","          23       0.54      0.37      0.44       150\n","          24       0.24      0.10      0.14        90\n","          25       0.67      0.75      0.70       480\n","          26       0.70      0.66      0.68       180\n","          27       0.57      0.40      0.47        60\n","          28       0.64      0.45      0.53       150\n","          29       0.38      0.22      0.28        90\n","          30       0.40      0.27      0.32       150\n","          31       0.66      0.63      0.65       270\n","          32       0.24      0.73      0.36        60\n","          33       0.41      0.24      0.30       210\n","          34       0.37      0.22      0.27       120\n","          35       0.27      0.22      0.24       390\n","          36       0.51      0.46      0.48       120\n","          37       0.27      0.22      0.24        60\n","          38       0.47      0.42      0.44       690\n","          39       0.14      0.06      0.08        90\n","          40       0.70      0.42      0.53        90\n","          41       0.31      0.17      0.22        60\n","          42       0.44      0.30      0.36        90\n","\n","    accuracy                           0.52     12630\n","   macro avg       0.52      0.45      0.46     12630\n","weighted avg       0.55      0.52      0.53     12630\n","\n","ACCURACY of TRAINING DATA\n","0.8873727970618991\n","-------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-dVhfd5RM71h"},"source":[""],"execution_count":null,"outputs":[]}]}